{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Demo: MNIST for ML Beginners\n",
    "Before start using this, please select `Cell` - `All Output` - `Clear` to clear the old results. See [TensorFlow Tutorial](https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html) for details of the tutorial.\n",
    "\n",
    "# Loading MNIST training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Images\n",
    "![mnist.train.xs](https://www.tensorflow.org/versions/master/images/mnist-train-xs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check MNIST training images matrix shape\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show MNIST label data\n",
    "sample_label = mnist.train.labels[5]\n",
    "sample_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the image\n",
    "plt.imshow(sample_img).set_cmap('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Labels\n",
    "![mnist.train.ys](https://www.tensorflow.org/versions/master/images/mnist-train-ys.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check MNIST labels shape\n",
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show MNIST label data\n",
    "sample_label = mnist.train.labels[5]\n",
    "sample_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in a graph:\n",
    "![](https://www.tensorflow.org/versions/master/images/softmax-regression-scalargraph.png)\n",
    "\n",
    "## in a vector equation:\n",
    "![](https://www.tensorflow.org/versions/master/images/softmax-regression-vectorequation.png)\n",
    "\n",
    "## so that we'll have the weights like this:\n",
    "blue: positive weights, red: negative weights\n",
    "![](https://www.tensorflow.org/versions/master/images/softmax-weights.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax_37:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a neural network (softmax logistic regression)\n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b) # the equation\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent_40' type=NoOp>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the train step to minimize the cross entropy with SGD\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.0001).minimize(cross_entropy)\n",
    "train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Gradient Decent to find the optimal weights\n",
    "![](http://blog.datumbox.com/wp-content/uploads/2013/10/gradient-descent.png)\n",
    "From: [Machine Learning Blog & Software Development News](http://blog.datumbox.com/tuning-the-learning-rate-in-gradient-descent/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do 1000 times of mini-batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables and session\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# train the model mini batch with 100 elements, for 1K times\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8719\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy of the model\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Ajouter une cellule ou vous lancerez une initialisation, afficherez la valeur des poids avant et après une optimisation. Est-ce que les poids change effectivement avant et après l'optimisation ? \n",
    "\n",
    "\n",
    "* Modifier ce notebook pour afficher deux courbes montrant la progression du loss/accuracy sur le training/test une fois le training terminé. Vous pouvez pour cela utiliser matplotlib.pyplot\n",
    "\n",
    "\n",
    "* quelle courbe semble dominer et obtenir les meilleurs résultats?\n",
    "\n",
    "\n",
    "* Affichez les logs de l'évolution du training et du test pendant le training.\n",
    "\n",
    "\n",
    "* Pouvez vous imaginez une formule d'erreur différente ? Mettez-la en place et comparer les résultats.\n",
    "\n",
    "\n",
    "* Modifiez le learning rate de 0001 à 0.1. Quelle sont les conséquences ? Pourquoi ?\n",
    "\n",
    "\n",
    "* Ajouter un seed à python et un seed à tensorflow. Pouvez-vous en déduire l'importance du seed dans un entrainement ?\n",
    "\n",
    "\n",
    "* A présent, trouvez le learning rate le plus favorable\n",
    "\n",
    "\n",
    "* Essayez de rajouter un hidden layer constitué de 16 neurones. La structure passera ainsi de 764 -> 10 à 764 -> 16 -> 10. Le layer intermédiaire devra être constitué de poids et d'un bias. Initialiser les poids à zero est-il une bonne idée avec deux layers ? Pourquoi ? Arrivez-vous à atteindre les mêmes performances avec un layer additionnel ? Que pouvez-vous en déduire ? \n",
    "\n",
    "\n",
    "* Il existe d'autre algorithms basé sur la déscente de gradient utile pour optimiser vos variables, essayer de remplacer la version actuel par une version plus sophisticé. Documentez vous sur les différences exacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
